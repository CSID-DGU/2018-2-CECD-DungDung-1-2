{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean word embedding\n",
    "\n",
    "한국어 데이터셋을 읽고 word score 계산, tokenizing, word2vec 모델을 학습시키고 단어에 대한 벡터를 반환하는 클래스를 구현합니다.\n",
    "\n",
    "## 준비\n",
    "아래의 코드를 돌리기 위해서는 3가지의 pip install이 필요합니다\n",
    "\n",
    "    pip install soynlp\n",
    "    pip install gensim\n",
    "    pip install numpy==1.13, should downgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer, MaxScoreTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# pip install soynlp\n",
    "# pip install gensim\n",
    "# pip install numpy==1.13, should downgrade numpy\n",
    "\n",
    "# https://github.com/lovit/soynlp/\n",
    "# https://lovit.github.io/nlp/2018/04/09/three_tokenizers_soynlp/\n",
    "# https://ratsgo.github.io/natural%20language%20processing/2017/03/08/word2vec/\n",
    "# https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "# 띄어쓰기 오류의 해결 (맞춤법 교정 툴 사용)\n",
    "# 학습되지 않은 단어에 대한 encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedQAData\n",
    "\n",
    "EmbedQAData의 생성자에는 열고자 하는 데이터셋의 파일 이름이 매개변수로 필요하며, 기본적으로 .xlsx 파일을 사용하도록 되어있습니다.\n",
    "\n",
    "생성자 실행 시, 읽어온 데이터셋을 바탕으로 word score 계산 -> tokenizer 설정 -> word2vec 모델 학습 및 저장이 이루어지게 됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbedQAData:\n",
    "    def __init__(self, fileName):\n",
    "        self.open_fileName = fileName\n",
    "        self.save_fileName = self.open_fileName + '_word2vec'\n",
    "        \n",
    "        self.question = pd.read_excel(self.open_fileName + '.xlsx')['question']\n",
    "        print(' read question data from ', self.open_fileName)\n",
    "        \n",
    "        self.setWordScores()\n",
    "        self.setTokenizer()\n",
    "        self.saveWord2Vec()\n",
    "        \n",
    "    def setWordScores(self):   \n",
    "        word_extractor = WordExtractor(\n",
    "            max_left_length=20, \n",
    "            max_right_length=20, \n",
    "            min_frequency = 20,\n",
    "            min_cohesion_forward = 0.05,\n",
    "            min_right_branching_entropy = 0.0\n",
    "        )\n",
    "        \n",
    "        word_extractor.train(self.question)\n",
    "        self.word_scores = word_extractor.extract()\n",
    "        print(' extract and calculate ', len(self.word_scores), ' words in ', self.open_fileName)\n",
    "    \n",
    "    def setTokenizer(self):\n",
    "        cohesion_scores = {word:score.cohesion_forward for word, score in self.word_scores.items()}\n",
    "        self.tokenizer = MaxScoreTokenizer(score = cohesion_scores)\n",
    "        # self.tokenizer = LTokenizer(scores = cohesion_scores)\n",
    "        print(' set tokenizer')\n",
    "        \n",
    "    def tokenizeSentence(self, sent):\n",
    "        tSent = [self.tokenizer.tokenize(s) for s in sent]\n",
    "        \n",
    "        return tSent\n",
    "                \n",
    "    def saveWord2Vec(self):\n",
    "        self.tQuestion = self.tokenizeSentence(self.question)\n",
    "        self.word2vec = Word2Vec(\n",
    "            self.tQuestion, \n",
    "            size = 100, \n",
    "            window = 2, \n",
    "            min_count = 30, \n",
    "            iter = 100, \n",
    "            sg = 1\n",
    "        )\n",
    "        \n",
    "        self.word2vec.save(self.save_fileName + '.model')\n",
    "        print(' train word2vec model and save model in ', self.save_fileName)\n",
    "        \n",
    "    def vectorizeWord(self, words):          \n",
    "        return self.word2vec.wv[words]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedQAData 객체 생성\n",
    "\n",
    "현재, '2018_11_10.xlsx' 데이터셋을 사용하도록 되어있습니다. 다른 데이터셋을 사용하고자 하실 경우 아래의 셀에서 파일명을 수정하여 주시기 바랍니다. 데이터셋과 본 코드는 같은 디렉토리에 있어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " read question data from  2018_11_10\n",
      "training was done. used memory 0.139 Gbry 0.136 Gb\n",
      "all cohesion probabilities was computed. # words = 1592\n",
      "all branching entropies was computed # words = 4190\n",
      "all accessor variety was computed # words = 4190\n",
      " extract and calculate  611  words in  2018_11_10\n",
      " set tokenizer\n",
      " train word2vec model and save model in  2018_11_10_word2vec\n"
     ]
    }
   ],
   "source": [
    "embed = EmbedQAData('2018_11_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedQAData 내의 word2vec 모델 활용\n",
    "\n",
    "embed.word2vec.wv.most_similar(word, topn = n) 함수는 데이터셋 내에 포함된 단어 중, word와 가장 유사한 n개의 단어와 유사도를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('확률및랜덤프로세스', 0.978531002998352), ('형식언어', 0.9780620336532593), ('공개sw프로젝트', 0.9758005738258362), ('ICT와소프트웨어', 0.9753122329711914), ('이산구조', 0.9732568860054016), ('종합설계', 0.9726034998893738), ('창의적공학설계', 0.9697827100753784), ('정보통신시스템시뮬레이션', 0.7893610596656799), ('sw비지니스와창업', 0.7745636701583862), ('네트워크보안', 0.7722445130348206), ('웹프로그래밍', 0.7705057859420776), ('자료구조와실습', 0.7702228426933289), ('시스템소프트웨어실습', 0.7693858742713928), ('비쥬얼프로그래밍', 0.7686390280723572), ('신호와시스템', 0.7679079174995422), ('무선통신및실험', 0.767259955406189), ('통신이론및실험', 0.766333281993866), ('인공지능', 0.7657416462898254), ('테크니컬프리젠테이션', 0.7636289000511169), ('웹플랫폼콘텐츠개발', 0.7617589235305786), ('증강혼합현실', 0.7609738111495972), ('안드로이드앱프로그래밍', 0.7601668834686279), ('OSS프로그래밍개발방법론', 0.7592142820358276), ('인터넷네트워킹', 0.7589564919471741), ('게임및로봇지능', 0.7549275159835815), ('초고속통신망', 0.7547352910041809), ('인간컴퓨터상호작용시스템', 0.7530588507652283), ('임베디드소프트웨어입문', 0.7521194219589233), ('가상현실', 0.752109944820404), ('인터넷프로그래밍', 0.7517735362052917), ('머신러닝', 0.7489280104637146), ('심화프로그래밍', 0.747812807559967), ('암호학과네트워크보안', 0.7453160285949707), ('계산적사고법', 0.7451678514480591), ('동시성프로그래밍', 0.7445386052131653), ('임베디드시스템', 0.7411622405052185), ('컴파일러구성', 0.73844313621521), ('S/W품질관리및테스팅', 0.7334628105163574), ('기초프로그래밍', 0.6196939945220947), ('병렬프로그래밍', 0.5882429480552673), ('사운드개론', 0.5873858332633972), ('알고리즘및실습', 0.5856925845146179), ('네트워킹', 0.5855941772460938), ('자료구조', 0.5855146646499634), ('그래밍기초와실습', 0.584208071231842)]\n"
     ]
    }
   ],
   "source": [
    "print(embed.word2vec.wv.most_similar('운영체제', topn=45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmbedQAData를 통한 단어 vectorize\n",
    "\n",
    "\n",
    "embed.vectorizeWord(word) 함수는 word에 대응하는 벡터를 반환하며, 이는 문자열 분류 딥러닝 모델의 입력으로서 사용 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14703494  0.07003424 -0.07532252  0.2090735   0.23807326 -0.39866677\n",
      "   0.12116498  0.26162276  0.16038509  0.11868048 -0.09329566  0.04649542\n",
      "   0.25153664  0.48589748 -0.12524371  0.51430911 -0.14833455  0.60317266\n",
      "   0.16239899 -0.41450891  0.1486879  -0.05780003  0.0558086  -0.20388298\n",
      "  -0.28821549 -0.43740484  0.55810088 -0.27375475 -0.38436699  0.46118206\n",
      "  -0.02095545  0.22825168  0.08149022 -0.3376433  -0.46305653 -0.47918421\n",
      "   0.14156145  0.21566027 -0.00966598 -0.57200462  0.05379961  0.23373818\n",
      "   0.35211366 -0.49744651  0.08418851  0.2943913  -0.76034296 -0.10517261\n",
      "   0.28527269  0.06699755 -0.5476442   0.07141912  0.17617524 -0.33091044\n",
      "   0.23739529  0.01365994 -0.08067644  0.53982013 -0.10116026 -0.03791698\n",
      "   0.11387751  0.08742219 -0.51501119 -0.22153682 -0.37704751 -0.23892644\n",
      "  -0.05746894 -0.16092631  0.11809233  0.35424164  0.03903409  0.22147048\n",
      "   0.13047653 -0.37080708  0.09219976 -0.10861404 -0.53251064  0.14750987\n",
      "   0.08352289  0.09339508  0.16494358 -0.33952382  0.23581022  0.58899236\n",
      "  -0.38271621  0.16380745  0.14309987 -0.26869482  0.30156437  0.14813828\n",
      "   0.56603962 -0.3542718  -0.38090539 -0.28164113  0.21152942  0.22996733\n",
      "   0.02849565 -0.31418407  0.08185767 -0.00848312]]\n"
     ]
    }
   ],
   "source": [
    "temp = ['김동호']\n",
    "\n",
    "print(embed.vectorizeWord(temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
